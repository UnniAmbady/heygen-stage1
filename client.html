<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>HeyGen Streaming — Interactive Avatar</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; margin:0; padding:16px; }
      #wrap { display:grid; gap:12px; max-width: 900px; margin: 0 auto; }
      video { width: 100%; aspect-ratio: 16/9; background:#000; border-radius: 12px; }
      .row { display:grid; gap:8px; grid-template-columns: repeat(3, 1fr); }
      button { padding: 10px 12px; border-radius: 10px; border: 1px solid #ddd; cursor: pointer; }
      button:disabled { opacity: .6; cursor: not-allowed; }
      .muted { font-size: 12px; color: #666; }
      #log { font: 12px/1.45 ui-monospace, Menlo, Consolas, monospace; white-space: pre-wrap; background:#f6f8fa; padding:10px; border:1px solid #e5e7eb; border-radius:8px; max-height:260px; overflow:auto; }
      .pill { padding: 2px 8px; border-radius: 999px; border:1px solid #ddd; }
      .ok  { color:#065f46; background:#ecfdf5; border-color:#a7f3d0; }
      .bad { color:#991b1b; background:#fef2f2; border-color:#fecaca; }
      .controls { display:flex; gap:8px; flex-wrap:wrap; align-items:center; }
    </style>
  </head>
  <body>
    <div id="wrap">
      <div class="controls muted">
        Status: <span id="status">Initializing stream…</span>
        <span id="rtc" class="pill">RTC: …</span>
        <span id="tok" class="pill">Token: …</span>
        <button id="micBtn" class="pill">Mic: off</button>
      </div>

      <video id="avatarVideo" autoplay playsinline muted></video>

      <div class="row">
        <button id="btn1" disabled>Say line 1</button>
        <button id="btn2" disabled>Say line 2</button>
        <button id="btn3" disabled>Say line 3</button>
      </div>

      <div id="log"></div>
    </div>

    <script type="module">
      import * as SDK from "https://cdn.jsdelivr.net/npm/@heygen/streaming-avatar/+esm";
      const { StreamingAvatar, StreamingEvents, TaskType } = SDK;

      // Values injected by Streamlit
      const TOKEN    = "__TOKEN__";
      const AVATARID = "__AVATAR_ID__";
      const VOICEID  = "__VOICE_ID__";
      const L1="__LINE1__", L2="__LINE2__", L3="__LINE3__";

      const videoEl  = document.getElementById('avatarVideo');
      const statusEl = document.getElementById('status');
      const btns     = [document.getElementById('btn1'), document.getElementById('btn2'), document.getElementById('btn3')];
      const rtcEl    = document.getElementById('rtc');
      const tokEl    = document.getElementById('tok');
      const micBtn   = document.getElementById('micBtn');
      const logEl    = document.getElementById('log');
      const log = (...a) => { logEl.textContent += a.join(" ") + "\n"; logEl.scrollTop = logEl.scrollHeight; };

      // Diagnostics
      const hasRTC = !!window.RTCPeerConnection;
      rtcEl.textContent = `RTC: ${hasRTC ? "ok" : "missing"}`;
      rtcEl.className = `pill ${hasRTC ? "ok":"bad"}`;
      tokEl.textContent = `Token: len=${(TOKEN||"").length}`;
      tokEl.className = `pill ${TOKEN && TOKEN.length>20 ? "ok":"bad"}`;

      // Init SDK
      const avatar = new StreamingAvatar({ token: TOKEN });
      if (avatar.setVideoElement) {
        try { avatar.setVideoElement(videoEl); } catch (e) { log("setVideoElement error:", e?.message || e); }
      }

      let streamReady = false;
      let firstSpeakDone = false;
      let micOn = false, micStream = null;

      // Watchdog
      setTimeout(() => {
        if (!streamReady) {
          statusEl.textContent = "No stream after 3s — verify Interactive avatar, Streaming access, and network/WebRTC.";
          log("[WATCHDOG] STREAM_READY not received within 3s.");
        }
      }, 3000);

      // Events
      avatar.on(StreamingEvents.STREAM_READY, (evt) => {
        streamReady = true;
        log("[EVENT] STREAM_READY");
        try {
          if (evt?.detail) videoEl.srcObject = evt.detail;
          statusEl.textContent = "Avatar is live — click a button to speak.";
          btns.forEach(b => b.disabled = false);
        } catch (e) {
          log("attach video error:", e?.message || e);
          statusEl.textContent = "Video attach failed. See logs.";
        }
      });

      avatar.on(StreamingEvents.ERROR, (evt) => {
        const err = evt?.detail || evt;
        log("[EVENT] ERROR:", typeof err === "string" ? err : JSON.stringify(err));
        statusEl.textContent = "SDK error (see logs).";
      });

      avatar.on(StreamingEvents.STREAM_DISCONNECTED, () => {
        log("[EVENT] STREAM_DISCONNECTED");
        statusEl.textContent = "Disconnected.";
      });

      avatar.on(StreamingEvents.AVATAR_START_TALKING, () => { statusEl.textContent = "Speaking…"; log("[EVENT] START_TALKING"); });
      avatar.on(StreamingEvents.AVATAR_STOP_TALKING,  () => { statusEl.textContent = "Idle.";       log("[EVENT] STOP_TALKING"); });

      // Start session
      (async () => {
        try {
          const opts = {
            avatarId: AVATARID,          // Interactive avatar
            quality: "low",
            voice: { voice_id: VOICEID } // from default_voice
          };
          log("createStartAvatar opts:", JSON.stringify(opts));
          const res = await avatar.createStartAvatar(opts);
          log("createStartAvatar ->", JSON.stringify(res));
        } catch (e) {
          statusEl.textContent = "Failed to start avatar. See logs.";
          log("createStartAvatar error:", e?.message || e);
        }
      })();

      // Speak helper (auto-unmute on first click)
      const speak = async (text) => {
        try {
          if (!firstSpeakDone) { try { videoEl.muted = false; await videoEl.play(); } catch {} firstSpeakDone = true; }
          log("speak:", text);
          await avatar.speak({ task_type: TaskType.REPEAT, text });
        } catch (e) {
          statusEl.textContent = "Speak failed.";
          log("speak error:", e?.message || e);
        }
      };
      btns[0].addEventListener('click', () => speak(L1));
      btns[1].addEventListener('click', () => speak(L2));
      btns[2].addEventListener('click', () => speak(L3));

      // Mic (two-way)
      const enableMic = async () => {
        try {
          micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          const track = micStream.getAudioTracks()[0];
          if (avatar.setMicrophoneEnabled) {
            avatar.setMicrophoneEnabled(true, track);
          } else if (avatar.setMicrophone) {
            await avatar.setMicrophone(micStream);
          }
          micOn = true;
          micBtn.textContent = "Mic: on";
          micBtn.className = "pill ok";
          log("Microphone enabled.");
        } catch (e) {
          log("Mic enable error:", e?.message || e);
          micBtn.textContent = "Mic: error";
          micBtn.className = "pill bad";
        }
      };
      const disableMic = () => {
        try { if (micStream) micStream.getTracks().forEach(t => t.stop()); } catch {}
        if (avatar.setMicrophoneEnabled) avatar.setMicrophoneEnabled(false);
        micOn = false;
        micBtn.textContent = "Mic: off";
        micBtn.className = "pill";
        log("Microphone disabled.");
      };
      micBtn.addEventListener('click', () => micOn ? disableMic() : enableMic());
    </script>
  </body>
</html>
